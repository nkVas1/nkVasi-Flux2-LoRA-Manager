# –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –Ω–æ–¥ FLUX.2 Training / Usage Guide

## üìã –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (Quick Start)

### 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞

–ü–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å:
- ‚úÖ sd-scripts —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã (https://github.com/kohya-ss/sd-scripts)
- ‚úÖ FLUX.2 –º–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞ (https://huggingface.co/black-forest-labs/FLUX.1-dev)
- ‚úÖ Dataset —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω
- ‚úÖ ComfyUI –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω (–Ω–æ–≤—ã–µ –Ω–æ–¥—ã –¥–æ–ª–∂–Ω—ã –ø–æ—è–≤–∏—Ç—å—Å—è)

### 2. –¢—Ä–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –Ω–æ–¥—ã

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Flux2_8GB_Config   ‚îÇ ‚Üê –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥ –∏ –∫–æ–º–∞–Ω–¥—É
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ (cmd_args, dataset_config, output_dir)
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Flux2_Run_External ‚îÇ ‚Üê –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É
‚îú‚îÄ cmd_args ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îú‚îÄ trigger (Bool)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           
           
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Flux2_Stop         ‚îÇ ‚Üê –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å
‚îú‚îÄ stop (Bool)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üöÄ –ü–æ—à–∞–≥–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ (Step-by-Step)

### –®–∞–≥ 1: –°–æ–∑–¥–∞—Ç—å –Ω–æ–¥—É Config

1. –û—Ç–∫—Ä–æ–π—Ç–µ ComfyUI
2. –î–æ–±–∞–≤—å—Ç–µ –Ω–æ–¥—É: Right-click ‚Üí "üõ†Ô∏è FLUX.2 Config (Low VRAM)"
3. –ó–∞–ø–æ–ª–Ω–∏—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:

```
sd_scripts_path    ‚Üí G:\ComfyUI-StableDif-t27-p312-cu128-v2.1\kohya_train\kohya_ss\sd-scripts
model_path         ‚Üí black-forest-labs/FLUX.1-dev
img_folder         ‚Üí G:\path\to\your\dataset\images
output_name        ‚Üí my_first_lora
resolution         ‚Üí 768 (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è 8GB VRAM)
learning_rate      ‚Üí 0.0001
max_train_steps    ‚Üí 1200
lora_rank          ‚Üí 16
enable_bucket      ‚Üí True
seed               ‚Üí 42
cache_to_disk      ‚Üí True
```

### –®–∞–≥ 2: –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–¥—É Runner

1. –î–æ–±–∞–≤—å—Ç–µ –Ω–æ–¥—É: Right-click ‚Üí "üöÄ Start Training (External)"
2. –ü–æ–¥–∫–ª—é—á–∏—Ç–µ `cmd_args` —Å Config –Ω–∞ –≤—Ö–æ–¥–µ Runner
3. **–ù–µ –º–µ–Ω—è–π—Ç–µ `trigger`, –æ—Å—Ç–∞–≤—å—Ç–µ False** (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)

### –®–∞–≥ 3: –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É

**–ü–µ—Ä–≤—ã–π —Ä–∞–∑:**
1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `trigger = True` –Ω–∞ Runner
2. –ù–∞–∂–º–∏—Ç–µ "Queue Prompt" (Ctrl+Enter)
3. –û–∂–∏–¥–∞–π—Ç–µ "‚úÖ Training Started!"
4. **–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `trigger = False`** (–≤–∞–∂–Ω–æ!)

**–í–æ –≤—Ä–µ–º—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏:**
- `trigger = False` ‚Üí –í–∏–¥–∏—Ç–µ –ª–æ–≥–∏, process —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ñ–æ–Ω–µ
- –ù–∞–∂–∏–º–∞–µ—Ç–µ "Queue Prompt" —Å–Ω–æ–≤–∞ ‚Üí –í–∏–¥–∏—Ç–µ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –ª–æ–≥–∏
- –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –ù–ï –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è ‚úÖ

### –®–∞–≥ 4: –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å (–µ—Å–ª–∏ –Ω—É–∂–Ω–∞)

1. –î–æ–±–∞–≤—å—Ç–µ –Ω–æ–¥—É: Right-click ‚Üí "üõë Emergency Stop"
2. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `stop = True`
3. –ù–∞–∂–º–∏—Ç–µ "Queue Prompt"
4. –û–∂–∏–¥–∞–π—Ç–µ "‚úÖ Stop signal sent"
5. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `stop = False`

## üõ†Ô∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Config –ù–æ–¥—ã

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–ø–∏—Å–∞–Ω–∏–µ |
|----------|----------|---------|
| `sd_scripts_path` | Path | –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ sd-scripts |
| `model_path` | HF Model ID –∏–ª–∏ Path | FLUX.1-dev –∏–ª–∏ local path |
| `img_folder` | Path | –ü–∞–ø–∫–∞ —Å training images |
| `output_name` | String | –ò–º—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ LoRA (–±–µ–∑ .safetensors) |
| `resolution` | 512, 768, 1024 | –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (768 —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) |
| `learning_rate` | Float (1e-5 to 1e-3) | –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è (1e-4 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) |
| `max_train_steps` | Int (100-5000) | –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ (1200 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é) |
| `lora_rank` | 16, 32 | –†–∞–∑–º–µ—Ä LoRA (16 = –ª–µ–≥—á–µ, 32 = –ª—É—á—à–µ) |
| `enable_bucket` | True/False | Bucketing –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–π |
| `seed` | Int | Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ |
| `cache_to_disk` | True/False | –ö—ç—à–∏—Ä–æ–≤–∞—Ç—å latents –Ω–∞ –¥–∏—Å–∫ (–æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç VRAM) |

## üìä –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è RTX 3060 Ti (8GB)

### –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞–º—è—Ç–∏

```
Total VRAM: 8GB
- FLUX.2 model (FP8): 2.5 GB
- LoRA + optimizer state: 1.5 GB
- Latent cache: 1.5 GB
- PyTorch overhead: 1.5 GB
- Free margin: 1 GB (–¥–ª—è stability)
‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
= 8 GB (tight fit!)
```

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è

```python
# –î–ª—è —É—Å–ø–µ—à–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –Ω–∞ 8GB:
resolution = 768              # –ù–µ –≤—ã—à–µ (512 –µ—Å–ª–∏ 4GB)
batch_size = 1                # –ù–ò–ö–û–ì–î–ê –≤—ã—à–µ 1 (–∂–µ—Å—Ç–∫–æ –≤ –∫–æ–¥–µ)
gradient_accumulation = 1     # 1 –¥–ª—è 8GB
learning_rate = 0.0001        # 1e-4 —Å—Ç–∞–Ω–¥–∞—Ä—Ç
optimizer = "adafactor"       # –õ–µ–≥—á–µ —á–µ–º AdamW
lora_rank = 16                # 32 —Å–ª–∏—à–∫–æ–º —Ç—è–∂–µ–ª–æ –¥–ª—è 8GB
cache_latents_to_disk = True  # –ö–†–ò–¢–ò–ß–ù–û –¥–ª—è 8GB
fp8_base = True               # –ö–≤–∞–Ω—Ç—É–µ—Ç –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
```

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞

### –õ–æ–≥–∏ –≤ ComfyUI

```
[FLUX-TRAIN] Running environment check...
[FLUX-TRAIN] ‚úì CUDA available
[FLUX-TRAIN] ‚úì PyTorch version correct
[FLUX-TRAIN] Ensuring training packages...
[FLUX-TRAIN] ‚úì All packages ready
[FLUX-TRAIN] --- TRAINING PROCESS STARTED ---
[FLUX-TRAIN] Loaded model: black-forest-labs/FLUX.1-dev
[FLUX-TRAIN] Dataset: 42 images found
[FLUX-TRAIN] Starting training loop...
[FLUX-TRAIN] Step 1/1200: loss=0.245, lr=0.0001
[FLUX-TRAIN] Step 2/1200: loss=0.241, lr=0.0001
...
```

### –§–∞–π–ª—ã –≤—ã–≤–æ–¥–∞

```
ComfyUI/output/flux_training/my_first_lora/
‚îú‚îÄ‚îÄ dataset.toml              # –ö–æ–Ω—Ñ–∏–≥ dataset
‚îú‚îÄ‚îÄ last.safetensors          # –ü–æ—Å–ª–µ–¥–Ω–∏–π checkpoint
‚îú‚îÄ‚îÄ diffusion_pytorch_model.safetensors  # Final LoRA weights
‚îî‚îÄ‚îÄ logs/
    ‚îî‚îÄ‚îÄ training_log.txt      # –ü–æ–ª–Ω—ã–π –ª–æ–≥ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
```

## ‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

### –ü—Ä–æ–±–ª–µ–º–∞: "No module named 'torch'"

**–†–µ—à–µ–Ω–∏–µ:**
```bash
python setup_training_env.py
# –ò–ª–∏ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å:
python setup_training_env.py --force
```

### –ü—Ä–æ–±–ª–µ–º–∞: "CUDA out of memory"

**–†–µ—à–µ–Ω–∏–µ:**
1. –£–º–µ–Ω—å—à–∏—Ç–µ `resolution` (—Å 768 –Ω–∞ 512)
2. –£–º–µ–Ω—å—à–∏—Ç–µ `lora_rank` (—Å 32 –Ω–∞ 16)
3. –í–∫–ª—é—á–∏—Ç–µ `cache_latents_to_disk`

### –ü—Ä–æ–±–ª–µ–º–∞: "cannot import name 'GenerationMixin'"

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# Delete old packages
rmdir /s training_libs
# Reinstall
python setup_training_env.py
```

### –ü—Ä–æ–±–ª–µ–º–∞: Dataset.toml –Ω–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å toml –ø–∞–∫–µ—Ç
pip install toml
# –ò–ª–∏ config –Ω–æ–¥–∞ —Å–∞–º–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JSON –≤–º–µ—Å—Ç–æ TOML
```

## üîç –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

### –ö–∞—Å—Ç–æ–º–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã

–ï—Å–ª–∏ –Ω—É–∂–Ω—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –æ—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ `src/config_gen.py` –∏ –¥–æ–±–∞–≤—å—Ç–µ:

```python
@classmethod
def INPUT_TYPES(cls):
    return {
        "required": {
            # ... existing ...
            "custom_param": ("STRING", {"default": "value"}),
        }
    }

def generate_config(self, ..., custom_param, ...):
    cmd.append("--custom_param")
    cmd.append(custom_param)
```

### –ù–µ—Å–∫–æ–ª—å–∫–æ LoRA —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ

**–í–Ω–∏–º–∞–Ω–∏–µ**: –ù–∞ –æ–¥–Ω–æ–π RTX 3060 Ti –≤–æ–∑–º–æ–∂–Ω–∞ —Ç–æ–ª—å–∫–æ 1 —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞. –ù–∞ RTX 4090 –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å 2, –Ω–æ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è.

### –ó–∞–≥—Ä—É–∑–∫–∞ –≤ ComfyUI

–ü–æ—Å–ª–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ LoRA –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤:
```
ComfyUI/output/flux_training/my_first_lora/diffusion_pytorch_model.safetensors
```

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≤ Node: Load LoRA
```
model_name ‚Üí my_first_lora.safetensors
```

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- **sd-scripts**: https://github.com/kohya-ss/sd-scripts
- **FLUX.1-dev**: https://huggingface.co/black-forest-labs/FLUX.1-dev
- **LoRA –æ–±—É—á–µ–Ω–∏–µ**: https://civitai.com/articles/guide-to-training-loras
- **Troubleshooting**: –°–º–æ—Ç—Ä–∏—Ç–µ TROUBLESHOOTING.md —ç—Ç–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞

## üí° –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏

1. **–ù–∞—á–Ω–∏—Ç–µ —Å –º–∞–ª–æ–≥–æ**: –°–Ω–∞—á–∞–ª–∞ 100 —à–∞–≥–æ–≤ –Ω–∞ test dataset, –∑–∞—Ç–µ–º –º–∞—Å—à—Ç–∞–±–∏—Ä—É–π—Ç–µ
2. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏**: –û—Ç–∫—Ä–æ–π—Ç–µ Task Manager, —Å–º–æ—Ç—Ä–∏—Ç–µ VRAM usage
3. **–°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ checkpoints**: sd-scripts —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç each 50/100 —à–∞–≥–æ–≤ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
4. **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–π dataset**: >30 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ö–æ—Ä–æ—à–µ–≥–æ LoRA
5. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å LR**: 1e-4 —Å—Ç–∞–Ω–¥–∞—Ä—Ç, –Ω–æ 1e-5 –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—É—á—à–µ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏

## üöÄ –ß—Ç–æ –¥–∞–ª—å—à–µ?

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ LoRA:

```
LoRA ‚Üí Use in generation nodes
    ‚Üí Refine with more data
    ‚Üí Merge with other LoRAs
    ‚Üí Upload to CivitAI
    ‚Üí Share community!
```

---

**Happy Training! üéâ**
